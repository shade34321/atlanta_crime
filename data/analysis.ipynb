{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv('COBRA-YTD2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.rename(columns={'UC2 Literal' : 'Crime', 'occur_time': 'time', 'MaxOfnum_victims': 'victims', 'Avg Day': 'day'}, inplace=True)\n",
    "# database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE : I removed rows where victims are only 1, it screws up the results.\n",
    "# database.day.unique()\n",
    "arr = [23, 24, 21, 19, 27, 17, 15]\n",
    "database = database[database.victims != 23]\n",
    "database = database[database.victims != 24]\n",
    "database = database[database.victims != 21]\n",
    "database = database[database.victims != 19]\n",
    "database = database[database.victims != 27]\n",
    "database = database[database.victims != 17]\n",
    "database = database[database.victims != 15]\n",
    "# database = database[database.Crime != 'LARCENY-FROM VEHICLE']\n",
    "array = database.Crime.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Clean up database and remove strings basically.\n",
    "\n",
    "arr = []\n",
    "\n",
    "# NOTE: Crime column.\n",
    "array = le.fit((np.array(database.Crime.unique())).tolist())\n",
    "database.Crime = le.transform((np.array(database.Crime)).tolist())\n",
    "\n",
    "# NOTE: Day column\n",
    "le.fit(np.array(database.day.unique()).tolist())\n",
    "database.day = le.transform((np.array(database.day)).tolist())\n",
    "\n",
    "# NOTE : Neighborhood\n",
    "le.fit(np.array(database.neighborhood.unique()).tolist())\n",
    "database.neighborhood = le.transform(np.array(database.neighborhood).tolist())\n",
    "\n",
    "database.victims = database.victims.fillna(0)\n",
    "\n",
    "# NOTE : Extract hour\n",
    "database['hour'] = pd.to_datetime(database.time).dt.hour\n",
    "\n",
    "# NOTE : Extract month\n",
    "database['month'] = pd.to_datetime(database.occur_date).dt.month\n",
    "\n",
    "# NOTE : Extract day\n",
    "database['days'] = pd.to_datetime(database.occur_date).dt.day\n",
    "\n",
    "# Take relevant data to different DataFrame\n",
    "df = database[['Crime', 'day', 'days', 'hour', 'victims', 'neighborhood', 'x', 'y', 'month']]\n",
    "\n",
    "# Make dummy variables\n",
    "df = df.join(pd.get_dummies(df.hour, prefix=\"hour\"))\n",
    "df = df.join(pd.get_dummies(df.days, prefix=\"days\"))\n",
    "df = df.join(pd.get_dummies(df.month, prefix=\"month\"))\n",
    "df = df.join(pd.get_dummies(df.day, prefix=\"day\"))\n",
    "\n",
    "arr = (database.groupby(['neighborhood']))['victims'].unique()\n",
    "count = (database.groupby(['neighborhood']))['victims'].nunique()\n",
    "\n",
    "# Did the LinearRegression thingy\n",
    "for i in range(0, database.neighborhood.nunique()):\n",
    "    arr[i] = sum(arr[i])/ count[i]\n",
    "    df.loc[df.neighborhood == i, 'victims'] = arr[i]\n",
    "    \n",
    "# df.victims = df.victims.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = df.drop(['victims'], 1)\n",
    "y_all = df['victims']\n",
    "\n",
    "X_all = X_all.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kbantupa\\documents\\github\\atlanta_crime\\env\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.133515950646736\n",
      "1.1461973540229362\n"
     ]
    }
   ],
   "source": [
    "# classif = OneVsRestClassifier(SVC(kernel = 'rbf'))\n",
    "# classif.fit(X_train, y_train)\n",
    "\n",
    "# classif = RandomForestClassifier()\n",
    "# classif = DecisionTreeClassifier(max_depth = 3)\n",
    "classif = LinearRegression()\n",
    "classif.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classif.predict(X_train)\n",
    "\n",
    "print(np.mean((y_pred - y_train) **2))\n",
    "\n",
    "# print(sum(y_train == y_pred) / float(len(y_pred)))\n",
    "# print(precision_score(y_train, y_pred, average='micro'))\n",
    "# print(recall_score(y_train, y_pred, average='weighted'))\n",
    "# print(f1_score(y_train, y_pred, average='macro'))\n",
    "\n",
    "y_pred = classif.predict(X_test)\n",
    "\n",
    "print(np.mean((y_pred - y_test) **2))\n",
    "# print(y_pred)\n",
    "\n",
    "# print(sum(y_test == y_pred) / float(len(y_pred)))\n",
    "# print(precision_score(y_test, y_pred, average='micro'))\n",
    "# print(f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
